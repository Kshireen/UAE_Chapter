{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from urllib.parse import unquote\n",
    "\n",
    "# Define the base URL for the API\n",
    "base_url = \"https://data.abudhabi/opendata\"\n",
    "\n",
    "# Define a list of API endpoint paths\n",
    "endpoint_paths = [\n",
    "    \"/api/1/metastore/schemas/dataset/items/dd41eed2-a2ca-4d9d-87b5-9fd9e93be8aa\",\n",
    "    \"/api/1/metastore/schemas/dataset/items/d284d312-9778-40e6-8d0c-85beba4ed48f\",\n",
    "    \"/api/1/metastore/schemas/dataset/items/b5c53b97-397c-4a35-9f09-e99ba59a72a7\",\n",
    "    \"/api/1/metastore/schemas/dataset/items/3103307a-6eff-4c68-850a-333df20d059d\",\n",
    "    \"/api/1/metastore/schemas/dataset/items/b1044f67-3a13-44a9-be19-acb8ab40f142\"\n",
    "    # Add more endpoint paths here as needed\n",
    "]\n",
    "\n",
    "# Create a list to store dataset information\n",
    "dataset_info_list = []\n",
    "\n",
    "# Loop through the endpoint paths\n",
    "for endpoint_path in endpoint_paths:\n",
    "    # Combine the base URL and endpoint path to form the full API URL\n",
    "    api_url = f\"{base_url}{endpoint_path}\"\n",
    "\n",
    "    try:\n",
    "        # Send an HTTP GET request to the API endpoint\n",
    "        response = requests.get(api_url)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Parse the JSON response containing data\n",
    "            data = response.json()\n",
    "\n",
    "            # Access the \"distribution\" field from the data\n",
    "            distributions = data.get('distribution')\n",
    "            if distributions:\n",
    "                # Iterate through the distribution items\n",
    "                for distribution in distributions:\n",
    "                    # Access and print the download URL\n",
    "                    download_url = distribution.get('downloadURL')\n",
    "                    if download_url:\n",
    "                        # Extract dataset name from the URL and decode it\n",
    "                        parts = download_url.split('/')\n",
    "                        dataset_name = unquote(parts[-1].split('.')[0])\n",
    "\n",
    "                        # Create a dictionary with the extracted information\n",
    "                        dataset_info = {\n",
    "                            \"dataset_name\": dataset_name,\n",
    "                            \"download_url\": download_url\n",
    "                        }\n",
    "\n",
    "                        # Append the dataset information to the list\n",
    "                        dataset_info_list.append(dataset_info)\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for endpoint {endpoint_path}. Status code: {response.status_code}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error for endpoint {endpoint_path}: {e}\")\n",
    "\n",
    "# Convert the list of dataset information to a JSON object\n",
    "dataset_info_json = json.dumps(dataset_info_list, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Print the JSON object\n",
    "print(dataset_info_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_connection import DataConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/laks007/Documents/AIML/omdena/local_chapters/project1/UAE_Open_Data_Intelligence/src/tasks/task_1_data_connection root folder path here\n"
     ]
    }
   ],
   "source": [
    "d_c=DataConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          year         Title_en           Title_ar Gender_en Gender_ar   value\n",
      "0  2014 / 2013          Schools            المدارس      Male      ذكور     259\n",
      "1  2014 / 2013  Teaching, staff  الهيئات التعليمية      Male      ذكور    6955\n",
      "2  2014 / 2013         Students             الطلاب      Male      ذكور  129382\n",
      "3  2014 / 2013          Schools            المدارس    Female      إناث     236\n",
      "4  2014 / 2013  Teaching, staff  الهيئات التعليمية    Female      إناث   17960\n"
     ]
    }
   ],
   "source": [
    "dset = 'Government Education'\n",
    "df = d_c.get_dataset(dset)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
