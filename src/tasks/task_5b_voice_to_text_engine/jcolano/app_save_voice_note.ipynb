{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "\n",
    "pip install sounddevice soundfile numpy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the recording parameters\n",
    "samplerate = 44100  # Sample rate (samples per second)\n",
    "duration = 10  # Duration (seconds)\n",
    "channels = 2  # Stereo\n",
    "filename = \"recorded_audio.wav\"  # Name of the file where audio will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording...\")\n",
    "# Record audio\n",
    "audio = sd.rec(int(samplerate * duration), samplerate=samplerate, channels=channels, dtype='float32')\n",
    "sd.wait()  # Wait until recording is complete\n",
    "print(\"Recording finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the audio\n",
    "sf.write(filename, audio, samplerate)\n",
    "print(f\"Audio saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the audio\n",
    "print(\"Playing the recorded audio...\")\n",
    "sd.play(audio, samplerate)\n",
    "sd.wait()  # Wait until audio playback is done\n",
    "\n",
    "print(\"Playback finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the audio data in a PyTorch tensor (audio_tensor), you can leverage the power of PyTorch to perform various operations on the data. Here are some potential uses:\n",
    "\n",
    "Deep Learning:\n",
    "\n",
    "Audio Classification: If you have a trained model, you can use the tensor to make predictions. For instance, you could classify sounds (e.g., dog barking, car honking, music playing) or recognize spoken commands.\n",
    "Training Models: If you collect multiple audio samples, you can use them to train deep learning models for various tasks, such as speech recognition, sound classification, or emotion detection from voice.\n",
    "Feature Extraction: You can use pre-trained models like VGGish or other architectures to extract meaningful features from the audio tensor and then use those features for classification or clustering tasks.\n",
    "Transformations:\n",
    "\n",
    "Spectrogram Generation: Convert the audio waveform to a spectrogram representation for visualization or to input into neural networks. This is often done in speech and audio processing before feeding the data into models.\n",
    "Augmentation: You can perform audio data augmentation, which is essential for training robust models. This includes operations like time stretching, pitch shifting, adding noise, etc.\n",
    "Analysis:\n",
    "\n",
    "Basic Statistics: Compute mean, variance, and other statistical measures of the audio signal.\n",
    "Feature Extraction: Extract audio features like Mel-frequency cepstral coefficients (MFCCs), chroma features, spectral contrast, etc., which can be used in traditional machine learning algorithms or for audio analysis.\n",
    "Manipulation:\n",
    "\n",
    "Filtering: Apply various filters to the audio data, like low-pass, high-pass, or band-pass filters.\n",
    "Volume Adjustment: Normalize or adjust the amplitude of the audio.\n",
    "Visualization:\n",
    "\n",
    "Waveform Plotting: Visualize the waveform of the audio signal to see its amplitude variations over time.\n",
    "Frequency Analysis: Visualize the frequency components of the audio signal using tools like Fourier transform.\n",
    "Integration with other Libraries:\n",
    "\n",
    "You can easily convert the PyTorch tensor to NumPy arrays (using .numpy()) and then utilize a vast array of scientific libraries available in Python for more specialized audio processing tasks.\n",
    "Custom Operations:\n",
    "\n",
    "Given that PyTorch is a deep learning library with auto-differentiation, you can define custom operations on the audio tensor and compute gradients, which might be useful for research purposes or custom applications.\n",
    "When working with audio data in deep learning, it's common to convert the raw waveform into a different representation (like spectrograms, MFCCs, etc.) because they can be more informative and lead to better model performance. The torchaudio library, which is an extension of PyTorch, provides many useful tools and transformations for working with audio data. If you plan on doing a lot with audio in PyTorch, you might want to look into torchaudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert audio data to PyTorch tensor\n",
    "audio_tensor = torch.tensor(audio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
