{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "\n",
    "def mp3_to_wav(filename):\n",
    "  \"\"\"\n",
    "  Convert .mp3 file format to .wav\n",
    "  using ffmpeg\n",
    "  \"\"\"\n",
    "  # load mp3 file\n",
    "  sound = AudioSegment.from_file(filename)\n",
    "  # rename file extension from .mp3 .wav\n",
    "  filename = 'audio.wav'\n",
    "  # save as wav file\n",
    "  sound.export(filename, format='wav')\n",
    "  return filename\n",
    "\n",
    "mp3_to_wav('sample.mp3')\n",
    "\n",
    "#load pre-trained model and tokenizer\n",
    "tokenizer1 = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model1 = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "#load any audio file of your choice\n",
    "speech, rate = librosa.load(\"audio.wav\",sr=16000)\n",
    "\n",
    "input_values = tokenizer1(speech, return_tensors = 'pt').input_values\n",
    "\n",
    "#Store logits (non-normalized predictions)\n",
    "logits = model1(input_values).logits\n",
    "\n",
    "#Store predicted id's\n",
    "predicted_ids = torch.argmax(logits, dim =-1)\n",
    "\n",
    "#decode the audio to generate text\n",
    "transcriptions = tokenizer1.decode(predicted_ids[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
